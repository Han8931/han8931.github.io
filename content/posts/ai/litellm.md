---
weight: 1
title: "LiteLLM: LLM Proxy Server"
date: 2025-09-18
draft: false
hiddenFromHomePage: true
author: Han
description: "A tutorial for llm proxy server and litellm"
tags: ["LLM Proxy server", "LiteLLM", "AI", "LLM"]
categories: ["LLM Proxy server", "LiteLLM", "LLM"]
---

LLM Proxy server is a way that adds much functionality like caching, rate limiting, and routing to making LLM requests. This blog post will explain what a proxy is and LiteLLM.

An LLM Proxy is a service that sits between your application and the LLM provider's API.
