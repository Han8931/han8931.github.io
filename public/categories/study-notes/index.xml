<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Study Notes on Han&#39;s XYZ</title>
    <link>http://localhost:1313/categories/study-notes/</link>
    <description>Recent content in Study Notes on Han&#39;s XYZ</description>
    <generator>Hugo</generator>
    <language>en</language>
    <managingEditor>tabularasa8931@gmail.com (Han)</managingEditor>
    <webMaster>tabularasa8931@gmail.com (Han)</webMaster>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Sun, 07 Sep 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/study-notes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Deep Statistical Learning</title>
      <link>http://localhost:1313/studynotes/deep_statistical_learning/</link>
      <pubDate>Sun, 07 Sep 2025 00:00:00 +0000</pubDate><author>tabularasa8931@gmail.com (Han)</author>
      <guid>http://localhost:1313/studynotes/deep_statistical_learning/</guid>
      <description>&lt;h1 id=&#34;-deep-statistical-learning&#34;&gt;ðŸ“– Deep Statistical Learning&lt;/h1&gt;&#xA;&lt;p&gt;ðŸ‘‰ Full repository: &lt;a href=&#34;https://github.com/Han8931/deep_statistical_learning&#34; target=&#34;_blank&#34; rel=&#34;noopener noreffer &#34;&gt;deep_statistical_learning&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;I started writing these notes during my &lt;strong&gt;masterâ€™s degree&lt;/strong&gt; as a way to organize and clarify my understanding of &lt;strong&gt;machine learning&lt;/strong&gt; and &lt;strong&gt;deep learning&lt;/strong&gt;. Over time, the notes have grown into a comprehensive study resource that combines theoretical foundations with practical insights.&lt;/p&gt;&#xA;&lt;p&gt;I enjoy organizing knowledge and writing things down, and these notes reflect that process â€” carefully breaking down concepts, connecting ideas, and recording them in a way that can be revisited and built upon.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reinforcement Learning</title>
      <link>http://localhost:1313/studynotes/reinforcement_learning/</link>
      <pubDate>Sun, 07 Sep 2025 00:00:00 +0000</pubDate><author>tabularasa8931@gmail.com (Han)</author>
      <guid>http://localhost:1313/studynotes/reinforcement_learning/</guid>
      <description>&lt;h1 id=&#34;-reinforcement-learning-notes&#34;&gt;ðŸ“˜ Reinforcement Learning Notes&lt;/h1&gt;&#xA;&lt;p&gt;ðŸ‘‰ You can check out the full notes here: &lt;a href=&#34;https://github.com/Han8931/reinforcement_learning_note&#34; target=&#34;_blank&#34; rel=&#34;noopener noreffer &#34;&gt;reinforcement_learning_note&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;There are already a number of excellent tutorials and lectures on &lt;strong&gt;Reinforcement Learning (RL)&lt;/strong&gt;, but I often find that many of them do not provide enough detail or explanation of the formulas behind the concepts. In many cases, key ideas are assumed to be &lt;em&gt;obvious&lt;/em&gt; or &lt;em&gt;straightforward&lt;/em&gt;â€”which can be a challenge for someone like me, who has a weaker background in mathematics but still wants a &lt;strong&gt;comprehensive understanding&lt;/strong&gt; of RL.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
